{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning with LSTM\n",
    "在这个练习中，你将用keras实现一个LSTM，并用来完成Image Caption的任务。\n",
    "\n",
    "在此之前，请先在`/cs231`目录下运行命令：python setup.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.image_utils import image_from_url\n",
    "import time, os, json\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft COCO\n",
    "数据集中，80000张图用于训练，40000张用于验证。每个图用5个标题（captions）。\n",
    "\n",
    "下载数据：http://cs231n.stanford.edu/coco_captioning.zip\n",
    "\n",
    "解压后放到`cs231n/datasets`目录下。\n",
    "\n",
    "数据用在ImageNet上预训练的VGG-16提取特征得到4096维的向量，并用pca降到512维。分别保存为`train2014_vgg16_fc7.h5` 、 `val2014_vgg16_fc7.h5`和`train2014_vgg16_fc7_pca.h5` 、 `val2014_vgg16_fc7_pca.h5`。\n",
    "\n",
    "图片的标题（caption）已经编码。每个词有一个整数ID，一个标题表示为一个整数序列。ID和单词间的对应关系存在文件`coco2014_vocab.json`中。你可以用`cs231n/coco_utils.py`中的函数`decode_captions`将numpy类型的ID序列转化为字符串。\n",
    "\n",
    "另外，还有一些特殊的符号。`<START>` 和`<END>`会被放在标题的开头和结尾。一些稀有的单词会用`<UNK>`代替。由于我们想用同一个模型训练不同长度的标题，因此在`<END>`后会补上一些`<NULL>`。\n",
    "\n",
    "下面的代码可以读取数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_coco_data(pca_features=True) # 默认读pca降维得到的数据\n",
    "\n",
    "# 读入的是一个字典，显示字典里各数据的类型\n",
    "for k, v in data.iteritems():\n",
    "  if type(v) == np.ndarray:\n",
    "    print k, type(v), v.shape, v.dtype\n",
    "  else:\n",
    "    print k, type(v), len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 显示两个实例，图片和标题（需要联网）\n",
    "# 遇到错误无法解决可以跳过此步\n",
    "batch_size = 3\n",
    "\n",
    "captions, features, urls = sample_coco_minibatch(data, batch_size=batch_size)\n",
    "for i, (caption, url) in enumerate(zip(captions, urls)):\n",
    "  plt.imshow(image_from_url(url))\n",
    "  plt.axis('off')\n",
    "  caption_str = decode_captions(caption, data['idx_to_word'])\n",
    "  plt.title(caption_str)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用LSTM实现Image Caption\n",
    "\n",
    "可以用one-hot的形式表示标题，用softmax来计算loss。\n",
    "\n",
    "注意，与分类模型不同。该模型在测试时与训练时明显不同。\n",
    "训练时我们将ground-truth的每个单词作为RNN每个时间点的输入。测试时则将上一个时间点的输出作为输入。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试\n",
    "\n",
    "通过 decode_captions(captions, data['idx_to_word']) 可以将numpy类型ID的整数序列转化为字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 抽样一些数据\n",
    "for split in ['train', 'val']:\n",
    "\n",
    "    minibatch = sample_coco_minibatch(data, split=split, batch_size=2)\n",
    "    gt_captions, features, urls = minibatch\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    sample_captions = # use yor model to predict\n",
    "    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "        plt.imshow(image_from_url(url))\n",
    "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
